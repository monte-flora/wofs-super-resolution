{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2e6bca",
   "metadata": {},
   "source": [
    "## Build the High-Resolution (1-km grid spacing) Reflectivity Dataset\n",
    "\n",
    "This notebooks generates the dataset for the super resolution work. The code opens the 1-km WoFS summary files and extracts a random patch of composite reflectivity from a random ensemble member. The final dataset is saved as float16 to enable additional samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fba3f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr \n",
    "\n",
    "from glob import glob\n",
    "import itertools\n",
    "\n",
    "# Adding wofs_super_res to the system path. \n",
    "from os.path import dirname, basename\n",
    "import sys, os ; sys.path.insert(0, dirname(dirname(os.getcwd())))\n",
    "path = os.path.dirname(os.getcwd())\n",
    "\n",
    "from wofs_super_res.util.resample import resample\n",
    "from wofs_super_res.util.filtering import SpatialFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a15f8ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH_1KM = '/work/brian.matilla/WOFS_2021/summary_files/WOFS_JET/WOFS_1KM/'\n",
    "BASE_PATH_3KM = '/work/mflora/SummaryFiles/'\n",
    "OUT_PATH = '/work/mflora/SUPER_RES/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3580ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the DBZ. \n",
    "def is_same_file(path_1km, path_3km):\n",
    "    return basename(path_1km) == basename(path_3km)\n",
    "\n",
    "def zip_files(paths_1km, paths_3km): \n",
    "    paths = []\n",
    "    for path_1km, path_3km in zip(paths_1km, paths_3km):\n",
    "        if is_same_file(path_1km, path_3km):\n",
    "            paths.append((path_1km, path_3km))\n",
    "    return paths \n",
    "\n",
    "def get_random_centroid(nx, delta):\n",
    "    \"\"\"Get random centroid\"\"\"\n",
    "    rng = np.arange(delta, nx-delta)\n",
    "    i,j = np.random.choice(rng, size=2, replace=False)\n",
    "    return i,j \n",
    "\n",
    "def save_dataset(fname, dataset):\n",
    "    \"\"\" saves xarray dataset to netcdf \"\"\"\n",
    "    comp = dict(zlib=True, complevel=5)\n",
    "    encoding = {var: comp for var in dataset.data_vars}\n",
    "    #os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "    dataset.to_netcdf( path = fname, encoding=encoding )\n",
    "    dataset.close( )\n",
    "    del dataset\n",
    "\n",
    "def generate_data(paths, save_fname):\n",
    "    \n",
    "    # patch size radius \n",
    "    patch_size = 60 # 120 x 120 patches \n",
    "    NX = 402\n",
    "    \n",
    "    dbz_1km_flt_set = []\n",
    "    dbz_1km_set = []\n",
    "    dbz_3km_set = [] \n",
    "    for path_1km, path_3km in paths:\n",
    "        \n",
    "        # Load the 1-km and 3-km reflectivity. \n",
    "        ds_1km = xr.load_dataset(path_1km, decode_times=False)\n",
    "        ds_3km = xr.load_dataset(path_3km, decode_times=False)\n",
    "        #i = np.random.choice(range(18), replace=False)\n",
    "        \n",
    "        # Get the lat,lon grids from the 1-km and 3-km \n",
    "        xlat_1km, xlon_1km = ds_1km['xlat'].values, ds_1km['xlon'].values\n",
    "        xlat_3km, xlon_3km = ds_3km['xlat'].values, ds_3km['xlon'].values\n",
    "        \n",
    "        # TODO: Grab a random ensemble member\n",
    "        ns = np.random.choice(range(18), size=3, replace=False)\n",
    "        for n in ns:\n",
    "            i,j = get_random_centroid(NX, patch_size)\n",
    "            dbz_1km = ds_1km['comp_dz'].values[n, i-patch_size:i+patch_size, j-patch_size:j+patch_size]\n",
    "            dbz_3km = ds_3km['comp_dz'].values[n,:,:]\n",
    "        \n",
    "            # Resample 3-km to 1-km \n",
    "            dbz_3km_res = resample(target_grid=(xlat_1km, xlon_1km), \n",
    "                    original_grid=(xlat_3km, xlon_3km), \n",
    "                    variable=dbz_3km)\n",
    "        \n",
    "            # Get the same patch from the 3-km data.\n",
    "            dbz_3km_res = dbz_3km_res[i-patch_size:i+patch_size, j-patch_size:j+patch_size]\n",
    "        \n",
    "            # Get the coordinates of the 1-km patch. \n",
    "            xlat_1km_res = xlat_1km[i-patch_size:i+patch_size, j-patch_size:j+patch_size]\n",
    "            xlon_1km_res = xlon_1km[i-patch_size:i+patch_size, j-patch_size:j+patch_size]\n",
    "\n",
    "            # Setting the minimal resolution as 6 km as that is the minimum resolution on\n",
    "            # a 3-km grid, but the effective resolution is likely larger. \n",
    "            flt = SpatialFilter(grid_spacing=1000, min_resolution=6000, filter_order=4)\n",
    "            dbz_1km_flt = flt.filter(dbz_1km)\n",
    "        \n",
    "            dbz_1km_flt_set.append(dbz_1km_flt[:-1, :-1])\n",
    "            dbz_1km_set.append(dbz_1km)\n",
    "            dbz_3km_set.append(dbz_3km_res)\n",
    "        \n",
    "    dbz_1km_flt_set = np.array(dbz_1km_flt_set, dtype=np.float32)\n",
    "    dbz_1km_set = np.array(dbz_1km_set, dtype=np.float32)\n",
    "    dbz_3km_set = np.array(dbz_3km_set, dtype=np.float32)\n",
    "    \n",
    "    # Convert to xarray dataset.\n",
    "    data = {}\n",
    "    \n",
    "    data['REFL_1KM'] = (['n_samples', 'ny', 'nx'], dbz_1km_set)\n",
    "    data['REFL_3KM'] = (['n_samples', 'ny', 'nx'], dbz_3km_set)\n",
    "    data['REFL_1KM_FILT'] = (['n_samples', 'ny', 'nx'], dbz_1km_flt_set)\n",
    "    data['xlat'] = (['ny', 'nx'], xlat_1km_res)\n",
    "    data['xlon'] = (['ny', 'nx'], xlon_1km_res)\n",
    "    \n",
    "    ds = xr.Dataset(data)\n",
    "    \n",
    "    save_dataset(save_fname, ds)\n",
    "    \n",
    "    return save_fname "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d21367a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fname' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m paths \u001b[38;5;241m=\u001b[39m zip_files(paths_1km[:\u001b[38;5;241m7\u001b[39m], paths_3km[:\u001b[38;5;241m7\u001b[39m])\n\u001b[1;32m     14\u001b[0m save_fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUT_PATH, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuper_res_patches_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00minit_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m ds_1km, ds_3km \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_fname\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [3], line 91\u001b[0m, in \u001b[0;36mgenerate_data\u001b[0;34m(paths, save_fname)\u001b[0m\n\u001b[1;32m     87\u001b[0m ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataset(data)\n\u001b[1;32m     89\u001b[0m save_dataset(save_fname, ds)\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfname\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fname' is not defined"
     ]
    }
   ],
   "source": [
    "dates = ['20210427',\n",
    " '20210518',\n",
    " '20210527',\n",
    " '20210523',\n",
    " '20210524',\n",
    " '20210514',\n",
    " '20210526',\n",
    " '20210519',\n",
    " '20210517',\n",
    " '20210504',\n",
    " '20210503'\n",
    "]\n",
    "\n",
    "init_times = ['0000',\n",
    " '0100',\n",
    " '0200',\n",
    " '0300',\n",
    " '1900',\n",
    " '2000',\n",
    " '2100',\n",
    " '2200',\n",
    " '2300',\n",
    "]\n",
    "# TODO: Add parallelization! \n",
    "# NOTE: If I use the 3-km as input, I'll have to manually resample it to a 3-km grid spacing\n",
    "# as it currently at a 1-km grid spacing. \n",
    "\n",
    "for date, init_time in itertools.product(dates, init_times):\n",
    "    paths_1km = glob(os.path.join(BASE_PATH_1KM, date, init_time, f'wofs_ENS_*'))\n",
    "    paths_3km = glob(os.path.join(BASE_PATH_3KM, date, init_time, f'wofs_ENS_*'))\n",
    "\n",
    "    paths_1km.sort()\n",
    "    paths_3km.sort()\n",
    "\n",
    "    # Only keep the first 15 min; forecasts errors are likely too large after that\n",
    "    # for a fair comparison of 3km -> 1km. \n",
    "    paths = zip_files(paths_1km[:3], paths_3km[:3])\n",
    "\n",
    "    save_fname = os.path.join(OUT_PATH, f'super_res_patches_{date}{init_time}.nc')\n",
    "    \n",
    "    ds_1km, ds_3km = generate_data(paths, save_fname)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d07aa667",
   "metadata": {},
   "source": [
    "# Plotting code to verify the patching and filtering is working. \n",
    "import matplotlib.pyplot as plt \n",
    "ds = generate_data(paths[:1])\n",
    "paths[:1]\n",
    "\n",
    "f, axes = plt.subplots(dpi=200, ncols=2, nrows=2, figsize=(10,10))\n",
    "\n",
    "axes[0,0].pcolormesh(ds['REFL_1KM'][0,:,:])\n",
    "axes[0,1].pcolormesh(ds['REFL_3KM'][0,:,:])\n",
    "axes[1,0].pcolormesh(ds['REFL_1KM_FILT'][0,:,:])\n",
    "\n",
    "titles = ['1-km Refl', '3-km Refl', '1-km Refl. (filtered)']\n",
    "\n",
    "for title, ax in zip(titles, axes.flat):\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65263635",
   "metadata": {},
   "source": [
    "ds_1km = xr.load_dataset(paths[0][0], decode_times=False)\n",
    "ds_3km = xr.load_dataset(paths[0][1], decode_times=False)\n",
    "\n",
    "xlat_1km, xlon_1km = ds_1km['xlat'].values, ds_1km['xlon'].values\n",
    "xlat_3km, xlon_3km = ds_3km['xlat'].values, ds_3km['xlon'].values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aef8792b",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "dbz_3km = ds_3km['comp_dz'].values[0,:,:]\n",
    "\n",
    "# Resample the 3-km data to the 1-km patch. \n",
    "dbz_3km_res = resample(target_grid=(xlat_1km, xlon_1km), \n",
    "                    original_grid=(xlat_3km, xlon_3km), \n",
    "                    variable=dbz_3km)\n",
    "\n",
    "f, axes = plt.subplots(dpi=200, ncols=2, figsize=(10,5))\n",
    "axes[0].pcolormesh(ds_1km['comp_dz'].values[0,:,:])\n",
    "axes[-1].pcolormesh(dbz_3km_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
